{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a871b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:05.520556Z",
     "iopub.status.busy": "2024-04-20T10:44:05.520178Z",
     "iopub.status.idle": "2024-04-20T10:44:21.943186Z",
     "shell.execute_reply": "2024-04-20T10:44:21.941930Z"
    },
    "papermill": {
     "duration": 16.431627,
     "end_time": "2024-04-20T10:44:21.945337",
     "exception": false,
     "start_time": "2024-04-20T10:44:05.513710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:44:08.462925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 10:44:08.463079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 10:44:08.616166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-aggregator-data-set/valid.txt\n",
      "/kaggle/input/news-aggregator-data-set/test.txt\n",
      "/kaggle/input/news-aggregator-data-set/train.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde247cd",
   "metadata": {
    "papermill": {
     "duration": 0.004254,
     "end_time": "2024-04-20T10:44:21.954367",
     "exception": false,
     "start_time": "2024-04-20T10:44:21.950113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5356e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:21.965016Z",
     "iopub.status.busy": "2024-04-20T10:44:21.964343Z",
     "iopub.status.idle": "2024-04-20T10:44:22.020433Z",
     "shell.execute_reply": "2024-04-20T10:44:22.019587Z"
    },
    "papermill": {
     "duration": 0.063999,
     "end_time": "2024-04-20T10:44:22.022715",
     "exception": false,
     "start_time": "2024-04-20T10:44:21.958716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- Read in the files\n",
    "- Assign the columns headers to the dataframe\n",
    "'''\n",
    "train_df = pd.read_csv('/kaggle/input/news-aggregator-data-set/train.txt', delimiter='\\t', header=None, encoding='utf-8')\n",
    "valid_df = pd.read_csv('/kaggle/input/news-aggregator-data-set/valid.txt', delimiter='\\t', header=None, encoding='utf-8')\n",
    "test_df = pd.read_csv('/kaggle/input/news-aggregator-data-set/test.txt', delimiter='\\t', header=None, encoding='utf-8')\n",
    "\n",
    "# Define the columns header\n",
    "columns = ['CATEGORY', 'TITLE']\n",
    "\n",
    "# Assign the headers to the dataframe\n",
    "train_df.columns = columns\n",
    "valid_df.columns = columns\n",
    "test_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d124a64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:22.033120Z",
     "iopub.status.busy": "2024-04-20T10:44:22.032806Z",
     "iopub.status.idle": "2024-04-20T10:44:22.079339Z",
     "shell.execute_reply": "2024-04-20T10:44:22.078353Z"
    },
    "papermill": {
     "duration": 0.054243,
     "end_time": "2024-04-20T10:44:22.081624",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.027381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>update 1 yellen prepares wall st for more whol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kanye raps about how awesome kim is on future ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>update 1 facebook to use satellites drones to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garth ancier counter sues michael egan over se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>update 1 mercedes recalls 284000 cars in us ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>mick jagger issues single statement regarding ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>rpt fitch affirms thailand s pttgc at aa tha o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>deutsche bank says health checks pose big unkn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>what kids actually think about sheryl sandberg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>us stocks snapshot wall st ends down with nasd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TITLE  LABEL\n",
       "0      update 1 yellen prepares wall st for more whol...      1\n",
       "1      kanye raps about how awesome kim is on future ...      0\n",
       "2      update 1 facebook to use satellites drones to ...      2\n",
       "3      garth ancier counter sues michael egan over se...      0\n",
       "4      update 1 mercedes recalls 284000 cars in us ca...      2\n",
       "...                                                  ...    ...\n",
       "10679  mick jagger issues single statement regarding ...      0\n",
       "10680  rpt fitch affirms thailand s pttgc at aa tha o...      1\n",
       "10681  deutsche bank says health checks pose big unkn...      1\n",
       "10682  what kids actually think about sheryl sandberg...      0\n",
       "10683  us stocks snapshot wall st ends down with nasd...      1\n",
       "\n",
       "[10684 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encode(df):\n",
    "    \"\"\"\n",
    "    Encode the 'CATEGORY' column of the DataFrame to numerical labels.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame containing the 'CATEGORY' column to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the 'CATEGORY' column replaced by numerical labels and the column renamed to 'LABEL'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map category labels to numerical labels\n",
    "    df.loc[df['CATEGORY'] == 'e', 'LABEL'] = 0\n",
    "    df.loc[df['CATEGORY'] == 'b', 'LABEL'] = 1\n",
    "    df.loc[df['CATEGORY'] == 't', 'LABEL'] = 2\n",
    "    df.loc[df['CATEGORY'] == 'm', 'LABEL'] = 3\n",
    "\n",
    "    # Drop the original 'CATEGORY' column if present\n",
    "    if 'CATEGORY' in df.keys():\n",
    "        df = df.drop('CATEGORY', axis='columns')\n",
    "\n",
    "    # Convert the 'LABEL' column to integer type\n",
    "    df['LABEL'] = df['LABEL'].astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = label_encode(train_df)\n",
    "valid_df = label_encode(valid_df)\n",
    "test_df = label_encode(test_df)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f21d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:22.092625Z",
     "iopub.status.busy": "2024-04-20T10:44:22.092299Z",
     "iopub.status.idle": "2024-04-20T10:44:22.099616Z",
     "shell.execute_reply": "2024-04-20T10:44:22.098658Z"
    },
    "papermill": {
     "duration": 0.015028,
     "end_time": "2024-04-20T10:44:22.101572",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.086544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \"\"\"\n",
    "    Create a balanced dataset by randomly sampling an equal number of samples for each class.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame containing the dataset to be balanced.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The balanced DataFrame with an equal number of samples for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the minimum number of samples among all classes\n",
    "    min_samples_count = min(df['LABEL'].value_counts())\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Extract an equal number of samples for each class\n",
    "    e = shuffled[shuffled['LABEL'] == 0][:min_samples_count]\n",
    "    b = shuffled[shuffled['LABEL'] == 1][:min_samples_count]\n",
    "    t = shuffled[shuffled['LABEL'] == 2][:min_samples_count]\n",
    "    m = shuffled[shuffled['LABEL'] == 3][:min_samples_count]\n",
    "\n",
    "    # Concatenate the sampled dataframes to create the balanced dataset\n",
    "    balanced_df = pd.concat([e, b, t, m], ignore_index=True)\n",
    "\n",
    "    # Shuffle the balanced dataset\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bd8264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:22.113054Z",
     "iopub.status.busy": "2024-04-20T10:44:22.112745Z",
     "iopub.status.idle": "2024-04-20T10:44:22.122260Z",
     "shell.execute_reply": "2024-04-20T10:44:22.121449Z"
    },
    "papermill": {
     "duration": 0.017587,
     "end_time": "2024-04-20T10:44:22.124353",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.106766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tokenizer_and_data_set(train_df, valid_df, test_df):\n",
    "    \"\"\"\n",
    "    Create tokenizer and prepare the dataset for training.\n",
    "\n",
    "    Args:\n",
    "    train_df (DataFrame): DataFrame containing the training data.\n",
    "    valid_df (DataFrame): DataFrame containing the validation data.\n",
    "    test_df (DataFrame): DataFrame containing the test data.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: A tuple containing tokenizer, vocabulary size, maximum sequence length,\n",
    "           training data, validation data, test data, training labels, validation labels, and test labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine titles from all datasets for tokenizer fitting\n",
    "    texts_to_fit = []\n",
    "    texts_to_fit.extend(train_df['TITLE'])\n",
    "    texts_to_fit.extend(valid_df['TITLE'])\n",
    "    texts_to_fit.extend(test_df['TITLE'])\n",
    "\n",
    "    # Define tokenizer with vocabulary size\n",
    "    n_most_common_words = 8000\n",
    "    tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(texts_to_fit)\n",
    "    \n",
    "    # Save Tokenizer to file\n",
    "    with open('tokenizer.pickle', 'wb') as handle:\n",
    "       pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Convert texts to sequences and find maximum sequence length\n",
    "    sequences = tokenizer.texts_to_sequences(texts_to_fit)\n",
    "    max_len = len(max(sequences, key=len))\n",
    "\n",
    "    # Define vocabulary size\n",
    "    vocabulary_size = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    # Pad sequences for train, valid, and test datasets\n",
    "    X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['TITLE'].values), maxlen=max_len)\n",
    "    X_valid = pad_sequences(tokenizer.texts_to_sequences(valid_df['TITLE'].values), maxlen=max_len)\n",
    "    X_test = pad_sequences(tokenizer.texts_to_sequences(test_df['TITLE'].values), maxlen=max_len)\n",
    "\n",
    "    # Convert labels to one-hot encoded format\n",
    "    y_train = to_categorical(train_df['LABEL'], num_classes=4)\n",
    "    y_valid = to_categorical(valid_df['LABEL'], num_classes=4)\n",
    "    y_test = to_categorical(test_df['LABEL'], num_classes=4)\n",
    "    \n",
    "    return tokenizer, vocabulary_size, max_len, X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a02165",
   "metadata": {
    "papermill": {
     "duration": 0.004677,
     "end_time": "2024-04-20T10:44:22.134196",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.129519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Create and Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b767706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:22.146279Z",
     "iopub.status.busy": "2024-04-20T10:44:22.145938Z",
     "iopub.status.idle": "2024-04-20T10:44:22.156428Z",
     "shell.execute_reply": "2024-04-20T10:44:22.155581Z"
    },
    "papermill": {
     "duration": 0.018422,
     "end_time": "2024-04-20T10:44:22.158480",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.140058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_and_train_model(vocabulary_size, max_len, X_train, X_valid, y_train, y_valid, class_weight, num_layers, num_units, dropout, verbose=0):\n",
    "    \"\"\"\n",
    "    Create and train a sequential model using LSTM layers.\n",
    "\n",
    "    Args:\n",
    "    vocabulary_size (int): Size of the vocabulary.\n",
    "    max_len (int): Maximum sequence length.\n",
    "    X_train (numpy.ndarray): Training data.\n",
    "    X_valid (numpy.ndarray): Validation data.\n",
    "    y_train (numpy.ndarray): Training labels.\n",
    "    y_valid (numpy.ndarray): Validation labels.\n",
    "    class_weight (dict): Dictionary containing class weights.\n",
    "    num_layers (int): Number of LSTM layers.\n",
    "    num_units (int): Number of units in each LSTM layer.\n",
    "    dropout (float): Dropout rate.\n",
    "    verbose (int): Verbose for model fit.\n",
    "\n",
    "    Returns:\n",
    "    float: Validation loss of the trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    epochs = 30\n",
    "    emb_dim = 200\n",
    "    batch_size = 256\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_len,)))\n",
    "    model.add(Embedding(input_dim=vocabulary_size, output_dim=emb_dim))\n",
    "    model.add(SpatialDropout1D(dropout))\n",
    "    for i in range(num_layers):\n",
    "        if i != num_layers - 1:\n",
    "            model.add(LSTM(num_units, dropout=dropout, recurrent_dropout=dropout, return_sequences=True))\n",
    "        else:\n",
    "            model.add(LSTM(num_units, dropout=dropout, recurrent_dropout=dropout))\n",
    "            \n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    # Initialize a checkpoint to save the model with the best validation loss\n",
    "    checkpoint_path = \"best_model.keras\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=7, min_delta=0.0001)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid),\n",
    "                        class_weight=class_weight, verbose=verbose, callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    accr = model.evaluate(X_valid, y_valid, verbose=verbose)\n",
    "    \n",
    "    # Return the validation loss\n",
    "    return accr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df81632",
   "metadata": {
    "papermill": {
     "duration": 0.004563,
     "end_time": "2024-04-20T10:44:22.167800",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.163237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Hyper Parameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdffb338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T10:44:22.178391Z",
     "iopub.status.busy": "2024-04-20T10:44:22.178096Z",
     "iopub.status.idle": "2024-04-20T11:20:38.209754Z",
     "shell.execute_reply": "2024-04-20T11:20:38.208800Z"
    },
    "papermill": {
     "duration": 2176.046022,
     "end_time": "2024-04-20T11:20:38.218477",
     "exception": false,
     "start_time": "2024-04-20T10:44:22.172455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [36:15<00:00, 43.51s/trial, best loss: 0.36765602231025696]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.5456938443766727, 'num_layers': 1.0, 'num_units': 8.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a balanced dataset for the validation set\n",
    "valid_df = create_balanced_dataset(valid_df)\n",
    "\n",
    "# Tokenize the text data and create datasets for training, validation, and testing\n",
    "tokenizer, vocabulary_size, max_len, X_train, X_valid, X_test, y_train, y_valid, y_test = create_tokenizer_and_data_set(train_df, valid_df, test_df)\n",
    "\n",
    "# Calculate class weights for imbalance correction\n",
    "class_counts = train_df['LABEL'].value_counts().to_dict()\n",
    "total_samples = sum(class_counts.values())\n",
    "class_weight = {}\n",
    "for clss, count in class_counts.items():\n",
    "    class_weight[clss] = total_samples / (len(class_counts) * count)\n",
    "\n",
    "# Define the function for training with hyperparameter optimization\n",
    "def train_fn(params):\n",
    "    num_layers = int(params['num_layers'])\n",
    "    num_units = int(params['num_units'])\n",
    "    dropout = params['dropout']\n",
    "\n",
    "    loss, accuracy = create_and_train_model(vocabulary_size, max_len, X_train, X_valid, y_train, y_valid, class_weight, num_layers, num_units, dropout)\n",
    "        \n",
    "    return loss\n",
    "\n",
    "# Perform hyperparameter optimization using Bayesian optimization\n",
    "best = fmin(fn=train_fn,\n",
    "            space={\n",
    "                'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "                'num_units': hp.quniform('num_units', 8, 32, 8), \n",
    "                'dropout': hp.uniform('dropout', 0.1, 0.8)  \n",
    "            },\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50)\n",
    "\n",
    "# Return the best hyperparameters found during optimization\n",
    "best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b1e9e",
   "metadata": {
    "papermill": {
     "duration": 0.008722,
     "end_time": "2024-04-20T11:20:38.236339",
     "exception": false,
     "start_time": "2024-04-20T11:20:38.227617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Retrain with best Hyper Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2453f5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T11:20:38.256354Z",
     "iopub.status.busy": "2024-04-20T11:20:38.256029Z",
     "iopub.status.idle": "2024-04-20T11:21:06.519813Z",
     "shell.execute_reply": "2024-04-20T11:21:06.518851Z"
    },
    "papermill": {
     "duration": 28.27621,
     "end_time": "2024-04-20T11:21:06.522109",
     "exception": false,
     "start_time": "2024-04-20T11:20:38.245899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - acc: 0.3297 - loss: 1.3772 - val_acc: 0.6756 - val_loss: 1.3313\n",
      "Epoch 2/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - acc: 0.6690 - loss: 1.3090 - val_acc: 0.7321 - val_loss: 1.1604\n",
      "Epoch 3/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - acc: 0.8010 - loss: 1.1000 - val_acc: 0.7917 - val_loss: 0.9220\n",
      "Epoch 4/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - acc: 0.8397 - loss: 0.8812 - val_acc: 0.8244 - val_loss: 0.7410\n",
      "Epoch 5/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - acc: 0.8860 - loss: 0.6568 - val_acc: 0.8423 - val_loss: 0.6057\n",
      "Epoch 6/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - acc: 0.9036 - loss: 0.5085 - val_acc: 0.8661 - val_loss: 0.5179\n",
      "Epoch 7/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - acc: 0.9226 - loss: 0.3934 - val_acc: 0.8810 - val_loss: 0.4603\n",
      "Epoch 8/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - acc: 0.9379 - loss: 0.3050 - val_acc: 0.8869 - val_loss: 0.4286\n",
      "Epoch 9/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - acc: 0.9482 - loss: 0.2510 - val_acc: 0.8899 - val_loss: 0.4158\n",
      "Epoch 10/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - acc: 0.9491 - loss: 0.2194 - val_acc: 0.8899 - val_loss: 0.4074\n",
      "Epoch 11/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - acc: 0.9560 - loss: 0.1814 - val_acc: 0.8929 - val_loss: 0.3941\n",
      "Epoch 12/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - acc: 0.9681 - loss: 0.1409 - val_acc: 0.8929 - val_loss: 0.3850\n",
      "Epoch 13/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - acc: 0.9692 - loss: 0.1365 - val_acc: 0.8988 - val_loss: 0.3913\n",
      "Epoch 14/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - acc: 0.9695 - loss: 0.1204 - val_acc: 0.8899 - val_loss: 0.4052\n",
      "Epoch 15/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.9716 - loss: 0.1094 - val_acc: 0.8839 - val_loss: 0.4143\n",
      "Epoch 16/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - acc: 0.9769 - loss: 0.0945 - val_acc: 0.8929 - val_loss: 0.4149\n",
      "Epoch 17/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.9787 - loss: 0.0837 - val_acc: 0.8988 - val_loss: 0.4112\n",
      "Epoch 18/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.9803 - loss: 0.0755 - val_acc: 0.8929 - val_loss: 0.4319\n",
      "Epoch 19/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - acc: 0.9840 - loss: 0.0658 - val_acc: 0.9018 - val_loss: 0.4262\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9169 - loss: 0.3110\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model with best hyper-parameters\n",
    "num_layers = int(best['num_layers'])\n",
    "num_units = int(best['num_units'])\n",
    "dropout = best['dropout']\n",
    "\n",
    "loss, accuracy = create_and_train_model(vocabulary_size, max_len, X_train, X_valid, y_train, y_valid, class_weight, num_layers, num_units, dropout, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffeec1",
   "metadata": {
    "papermill": {
     "duration": 0.045004,
     "end_time": "2024-04-20T11:21:06.609314",
     "exception": false,
     "start_time": "2024-04-20T11:21:06.564310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Evaluate the model with test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449fd611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T11:21:06.705064Z",
     "iopub.status.busy": "2024-04-20T11:21:06.704700Z",
     "iopub.status.idle": "2024-04-20T11:21:07.893951Z",
     "shell.execute_reply": "2024-04-20T11:21:07.893073Z"
    },
    "papermill": {
     "duration": 1.23601,
     "end_time": "2024-04-20T11:21:07.896292",
     "exception": false,
     "start_time": "2024-04-20T11:21:06.660282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,732,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_50 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │     \u001b[38;5;34m2,732,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_99 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m6,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,216,174</span> (31.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,216,174\u001b[0m (31.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,738,724</span> (10.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,738,724\u001b[0m (10.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,477,450</span> (20.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,477,450\u001b[0m (20.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Label: entertainment\n",
      "Precision: 0.973\n",
      "Recall: 0.943\n",
      "F1-score: 0.958\n",
      "\n",
      "Label: business\n",
      "Precision: 0.954\n",
      "Recall: 0.946\n",
      "F1-score: 0.950\n",
      "\n",
      "Label: science and technology\n",
      "Precision: 0.761\n",
      "Recall: 0.825\n",
      "F1-score: 0.792\n",
      "\n",
      "Label: health\n",
      "Precision: 0.728\n",
      "Recall: 0.798\n",
      "F1-score: 0.761\n",
      "\n",
      "Label: macro avg\n",
      "Precision: 0.854\n",
      "Recall: 0.878\n",
      "F1-score: 0.865\n",
      "\n",
      "Label: weighted avg\n",
      "Precision: 0.925\n",
      "Recall: 0.921\n",
      "F1-score: 0.923\n",
      "\n",
      "Macro-average:\n",
      "Precision: 0.854\n",
      "Recall: 0.878\n",
      "F1-score: 0.865\n"
     ]
    }
   ],
   "source": [
    "# Path to the saved model file\n",
    "model_path = '/kaggle/working/best_model.keras'\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Check the architecture of the loaded model\n",
    "model.summary()\n",
    "\n",
    "# Predict probabilities for each class for the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to predicted class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(y_test.argmax(axis=1), y_pred, target_names=['entertainment', 'business', 'science and technology', 'health'], output_dict=True)\n",
    "\n",
    "# Print precision, recall, and F1-score for each label and macro-average scores\n",
    "for label in report.keys():\n",
    "    if label != 'accuracy':\n",
    "        precision = report[label]['precision']\n",
    "        recall = report[label]['recall']\n",
    "        f1_score = report[label]['f1-score']\n",
    "        print(f\"Label: {label}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall: {recall:.3f}\")\n",
    "        print(f\"F1-score: {f1_score:.3f}\")\n",
    "        print()\n",
    "        \n",
    "# Print macro-average scores\n",
    "macro_precision = report['macro avg']['precision']\n",
    "macro_recall = report['macro avg']['recall']\n",
    "macro_f1_score = report['macro avg']['f1-score']\n",
    "print(\"Macro-average:\")\n",
    "print(f\"Precision: {macro_precision:.3f}\")\n",
    "print(f\"Recall: {macro_recall:.3f}\")\n",
    "print(f\"F1-score: {macro_f1_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4833378,
     "sourceId": 8168057,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2228.292103,
   "end_time": "2024-04-20T11:21:10.837101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-20T10:44:02.544998",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
